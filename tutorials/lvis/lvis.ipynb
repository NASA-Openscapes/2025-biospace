{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a25f05-03cf-4acb-9dce-877b16181538",
   "metadata": {},
   "source": [
    "# BIOSPACE25 Workshop: \n",
    "\n",
    "## Harnessing analysis tools for biodiversity applications using field, airborne, and orbital remote sensing data from NASA's BioSCAPE campaign\n",
    "\n",
    "Michele Thornton, Rupesh Shrestha, Erin Hestir, Adam Wilson, Jasper Slingsby, Anabelle Cardoso\n",
    "\n",
    "**Date:**  February 12, 2025, Frascati (Rome), Italy\n",
    "\n",
    "![BIOSPACE25](../avirisng/images/BioSpace25_clip_50.jpg)\n",
    "\n",
    "# Exploring and Visualizing BioSCape LVIS Data\n",
    "\n",
    "## Overview\n",
    "[**BioSCape**](https://www.bioscape.io/), the Biodiversity Survey of the Cape, is NASA’s first biodiversity-focused airborne and field campaign that was conducted in South Africa in 2023. BioSCape’s primary objective is to study the structure, function, and composition of the region’s ecosystems, and how and why they are changing. \n",
    "\n",
    "BioSCape's airborne dataset is unprecedented, with `AVIRIS-NG`, `PRISM`, and `HyTES` imaging spectrometers capturing spectral data across the UV, visible and infrared at high resolution and `LVIS` acquiring coincident full-waveform lidar. BioSCape's `field dataset` is equally impressive, with 18 PI-led projects collecting data ranging from the diversity and phylogeny of plants, kelp and phytoplankton, eDNA, landscape acoustics, plant traits, blue carbon accounting, and more\n",
    "\n",
    "This tutorial will demonstrate accessing and visualizing **Land, Vegetation, and Ice Sensor (LVIS)** data available on the BioSCape SMCE. LVIS is an airborne, wide-swath imaging full-waveform laser altimeter. LVIS collects in a 1064 nm-wavelength (near infrared) range with 3 detectors mounted in an airborne platform, flown typically ~10 km above the ground producing a data swath of 2km wide with 7-10 m footprints. More information about the LVIS instrument is [here](https://lvis.gsfc.nasa.gov/Home/instrumentdetails.html).\n",
    "\n",
    "The LVIS instrument has been flown above several regions of the world since 1998. The LVIS flights were collected for the [BioSCAPE campaigns](https://lvis.gsfc.nasa.gov/Data/Maps/SouthAfrica2023Map.html) from `01 Oct 2023` through `30 Nov 2023`.\n",
    "\n",
    "There are three LVIS BioSCape data products currently available and archived at [NSIDC DAAC](https://search.earthdata.nasa.gov/search?q=LVIS&qt=2023-10-20T00%3A00%3A00.000Z%2C2023-11-15T23%3A59%3A59.999Z&fi=LVIS-Camera!LVIS&fdc=National%2BSnow%2Band%2BIce%2BData%2BCenter%2BDistributed%2BActive%2BArchive%2BCenter%2B%2528NSIDC%2BDAAC%2529&fpj=BioSCape&_ga=2.63606251.53278573.1721067437-1362124365.1714395655&_gl=1*q0ghrk*_ga*MTM2MjEyNDM2NS4xNzE0Mzk1NjU1*_ga_LQ2P0SNJCZ*MTcyMTU5NTQ4Ni4xMjMuMS4xNzIxNTk1NjkxLjAuMC4w)\n",
    "\n",
    "| Dataset | Dataset DOI | \n",
    "| -------- | --- |\n",
    "| LVIS L1A Geotagged Images V001 | [10.5067/NE5KKKBAQG44](https://doi.org/10.5067/NE5KKKBAQG44) |\n",
    "| LVIS Facility L1B Geolocated Return Energy Waveforms V001 | [10.5067/XQJ8PN8FTIDG](https://doi.org/10.5067/XQJ8PN8FTIDG) |\n",
    "| LVIS Facility L2 Geolocated Surface Elevation and Canopy Height Product V001 | [10.5067/VP7J20HJQISD](https://doi.org/10.5067/VP7J20HJQISD) |\n",
    "\n",
    "For this tutorial, we'll examine the `LVIS L2 Geolocated Surface Elevation and Canopy Height Product V001`\n",
    "\n",
    "- **Citation:** Blair, J. B. & Hofton, M. (2020). LVIS Facility L2 Geolocated Surface Elevation and Canopy Height Product, Version 1 [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. https://doi.org/10.5067/VP7J20HJQISD.\n",
    "- **User Guide** [LVIS Facility L2 Geolocated Surface Elevation and Canopy Height Product, Version ](https://nsidc.org/sites/default/files/lvisf2-v001-userguide_2_0.pdf)1\n",
    "\n",
    "![LVIS Waveform](assets/lvis_waveform.png)\n",
    "**Figure:** Sample LVIS product waveforms illustrating possible distributions of reflected light (Blair et al., 2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97e651-d363-467d-b59d-200642012f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import earthaccess\n",
    "import geopandas as gpd\n",
    "import requests as re\n",
    "import s3fs\n",
    "import h5py\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "from shapely.ops import orient\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box\n",
    "import dill\n",
    "from harmony import BBox,Client, Collection, Request, LinkType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610f151-697a-4e29-bc37-23832a61c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install crepes dill xgboost pynndescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2ce4a-c1c4-4eb1-9961-ebecc7f0fd93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# esri background basemap for maps\n",
    "xyz = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n",
    "attr = \"ESRI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ec683-cfa3-4c43-a485-948f28827494",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "We recommend authenticating your Earthdata Login (EDL) information using the `earthaccess` python library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb726fa5-b0bf-439a-a8fa-4092152031bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# works if the EDL login already been persisted to a netrc\n",
    "try:\n",
    "    auth = earthaccess.login(strategy=\"netrc\")\n",
    "except FileNotFoundError:\n",
    "    # ask for EDL credentials and persist them in a .netrc file\n",
    "    auth = earthaccess.login(strategy=\"interactive\", persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44022ce9-609c-44b0-b9a3-baacfd5ee53e",
   "metadata": {},
   "source": [
    "## Structure LVIS L1B Geolocated Waveform\n",
    "\n",
    "First, let's find out how many L1B files from the BioSCape Campaign are published on NASA Earthdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e92f1c-7705-467c-bee5-2a8f73667293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doi=\"10.5067/XQJ8PN8FTIDG\" # LVIS L1B doi\n",
    "query = earthaccess.DataGranules().doi(doi)\n",
    "query.params['campaign'] = 'bioscape'\n",
    "l1b = query.get_all()\n",
    "print(f'Granules found: {len(l1b)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b6033-9a8f-4b67-b474-309df8b4ecaa",
   "metadata": {},
   "source": [
    "There are 2328 granules LVIS L1B product found for the time period. Let's see if they are hosted on Earthdata cloud or not, by printing a summary of the first granule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb8ffe4-49a6-4ba3-b535-4c083d44356b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l1b[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8802d-3e5c-4725-a5b2-06589c54af55",
   "metadata": {},
   "source": [
    "As we see above, the LVIS files are not cloud-hosted yet. They have to be downloaded locally and use them. We will go ahead and use earthaccess python module to get the file directly and save it to the `downloads` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c2390-4587-449a-a1c4-2031a77fae0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download files\n",
    "downloaded_files = earthaccess.download(l1b[0], local_path=\"downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3bc60e-2b2d-4a19-bd52-9d1a43df9c5c",
   "metadata": {},
   "source": [
    "Now, we go ahead and open a file to look at its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289fa230-014d-4343-8b43-94fc5c142ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l1b_first = f'downloads/{path.basename(l1b[0].data_links()[0])}'\n",
    "with h5py.File(l1b_first) as hf:\n",
    "    for v in list(hf.keys()):\n",
    "        if v != \"ancillary_data\":\n",
    "            print(f\"- {v} : {hf[v].attrs['description'][0].decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338cb08-5a9e-4c52-8d0c-6f5dc889cca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(l1b_first) as hf:\n",
    "    l_lat = hf['LAT1215'][:]\n",
    "    l_lon = hf['LON1215'][:]\n",
    "    l_range = hf['Z1215'][:] # ground elevation\n",
    "    shot = hf['SHOTNUMBER'][:] # ground elevation\n",
    "geo_arr = list(zip(shot, l_range,l_lat,l_lon))\n",
    "l1b_df = pd.DataFrame(geo_arr, columns=[\"shot_number\", \"elevation\", \"lat\", \"lon\"])\n",
    "l1b_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc2323-b7c1-44f4-92d1-ba1d94b643d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "l1b_gdf = gpd.GeoDataFrame(l1b_df, crs=\"EPSG:4326\",\n",
    "                           geometry=gpd.points_from_xy(l1b_df.lon, \n",
    "                                                       l1b_df.lat))\n",
    "l1b_gdf.sample(frac=0.01).explore(\"elevation\", cmap = \"plasma\", tiles=xyz, attr=attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb11ab-d494-4f38-9cff-727650d760c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = np.where(shot==1319816)[0][0]\n",
    "with h5py.File(l1b_first) as hf:\n",
    "    rxwaveform = hf['RXWAVE'][i, :] # waveform\n",
    "    elev_1215 = hf['Z1215'][i] # elevation ground\n",
    "    elev_0 = hf['Z0'][i] # elevation top\n",
    "c = len(rxwaveform) #\n",
    "elev = np.linspace(elev_1215, elev_0, num=c)\n",
    "# plot\n",
    "plt.rcParams[\"figure.figsize\"] = (3,10)\n",
    "plt.xlabel(\"rxwaveform (counts)\")\n",
    "plt.ylabel(\"elevation (m)\")\n",
    "plt.plot(rxwaveform, elev, linestyle='--', marker='.',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da66d8b-b521-4312-ba57-1d1828f352e4",
   "metadata": {},
   "source": [
    "## Structure of LVIS L2 Canopy Height Product\n",
    "First, let's search how many L2 files are there for the BioSCape campaign dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22753cf-c53e-445d-801a-33f084c74ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doi=\"10.5067/VP7J20HJQISD\" # LVIS L2 doi\n",
    "query = earthaccess.DataGranules().doi(doi)\n",
    "query.params['campaign'] = 'bioscape'\n",
    "l2 = query.get_all()\n",
    "print(f'Granules found: {len(l2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f39016-edb6-4edb-8cdf-1c1695c74145",
   "metadata": {},
   "source": [
    "There are 2328 granules LVIS L2 product found for the time period. Let's see if they are hosted on Earthdata cloud or not, by printing a summary of the first granule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4ca82-0fd8-4008-9532-cd420f58e30a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d7dda-f8c0-488a-a8f8-31c0cb048cc5",
   "metadata": {},
   "source": [
    "As we see above, the LVIS files are not cloud-hosted yet. They have to be downloaded locally and use them. We will go ahead and use earthaccess python module to get the file directly and save it to the `downloads` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee5880-c62e-4736-9635-a081b872463f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download files\n",
    "downloaded_files = earthaccess.download(l2[0], local_path=\"downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28340b-829c-4f53-8c21-54daf0b755e3",
   "metadata": {},
   "source": [
    "Now, we'll go ahead and open a file to look at it's structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f0982-f1d7-4689-a951-3a1a84b7f03a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l2_first = f'downloads/{path.basename(l2[0].data_links()[0])}'\n",
    "with open(l2_first, 'rb') as f:\n",
    "    head = [next(f) for _ in range(15)]\n",
    "    print(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457f399-45ce-4adb-a03c-0fd3be79d6f8",
   "metadata": {},
   "source": [
    "LVIS L2A files have a number of lines as header as shown above. Let's define a python function to read the number of header rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85a7c9-f8a7-4d18-a38e-d0c78077eaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_line_number(filename):\n",
    "    \"\"\"find number of header rows in LVIS L2A\"\"\"\n",
    "    count = 0\n",
    "    with open(filename, 'rb') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(b'#'):\n",
    "                count = count + 1\n",
    "                columns = line[1:].split()\n",
    "            else:\n",
    "                return count, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15365fe-9d91-4f60-9992-d479da3da5c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_no, col_names = get_line_number(l2_first)\n",
    "with open(l2_first, 'rb') as f:\n",
    "    l2a_df = pd.read_csv(f, skiprows=h_no, header=None, engine='python', sep=r'\\s+')\n",
    "    l2a_df.columns =  [x.decode() for x in col_names]\n",
    "l2a_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3107b-2437-4227-87a0-2cd880d8b61d",
   "metadata": {},
   "source": [
    "Let's print LVIS L2 variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6973a6ce-6f02-46e0-ade4-a3b1c4187e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l2a_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98398f28-2abd-4fe7-bb0e-efe91ac6b7d2",
   "metadata": {},
   "source": [
    "Key variables:\n",
    "- The `GLAT` and `GLON` variables provide coordinates of the lowest detected mode within the LVIS waveform.\n",
    "- The `RHXX` variables provide height above the lowest detected mode at which XX percentile of the waveform energy.\n",
    "- `RANGE` provides the distance from the instrument to the ground.\n",
    "- `SENSITIVITY` provides sensitivity metric for the return waveform.\n",
    "- `ZG`,`ZG_ALT1`, `ZG_ALT2`: Mean elevation of the lowest detected mode using alternate 1/2 mode detection settings. The alternative `ZG` to use to adjust the RH parameters for local site conditions.\n",
    "\n",
    "More information about the variables are provided in the [user guide](https://nsidc.org/sites/default/files/lvisf2-v001-userguide_2_0.pdf).\n",
    "\n",
    "Let's select the particular shot we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91043235-a863-4ea6-b04c-7d0af173fca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l2a_shot_df = l2a_df[l2a_df['SHOTNUMBER'] == 1319816]\n",
    "l2a_shot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669e5ab-b92b-4db3-a29d-71b9dfbff69d",
   "metadata": {},
   "source": [
    "Now, we can plot the RH metrics with elevation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268736c-410b-4258-9a40-b2ed47dfaa71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elev_zg = l2a_shot_df.ZG.values[0]\n",
    "elev_zh = l2a_shot_df.ZH.values[0]\n",
    "rh40 = l2a_shot_df.RH40.values[0]\n",
    "rh80 = l2a_shot_df.RH80.values[0]\n",
    "rh100 = l2a_shot_df.RH100.values[0]\n",
    "rh = l2a_shot_df.filter(like ='RH').drop('CHANNEL_RH', axis=1).values.tolist()[0]\n",
    "\n",
    "# plotting\n",
    "plt.rcParams[\"figure.figsize\"] = (5,7)\n",
    "rh_vals = l2a_shot_df.filter(like = 'RH').columns[:-1].str.strip('RH').astype(int).tolist()\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(rh_vals, elev_zg+rh, alpha=0.3, marker='o', color='black', label='RH metrics' )\n",
    "ax1.axhline(y=elev_zg+rh40,  color='g', linestyle='dotted', linewidth=2, label='RH40')\n",
    "ax1.axhline(y=elev_zg+rh80,  color='g', linestyle='-.', linewidth=2, label='RH80')\n",
    "ax1.axhline(y=elev_zg+rh100,  color='g', linestyle='--', linewidth=3, label='RH100')\n",
    "ax1.set_xlabel(\"Percentile of waveform energy (%)\")\n",
    "ax1.set_ylabel(\"elevation (meters)\")\n",
    "ax1.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f236eb-c429-4f4c-b9b9-474cb31a72c2",
   "metadata": {},
   "source": [
    "## Plot LVIS Bioscape Campaigns\n",
    "Lets first define two functions that we can use to plot the search results above over a basemap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641274a9-6053-4471-b318-cef919c236e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_umm_geometry(gpoly):\n",
    "    \"\"\"converts UMM geometry to multipolygons\"\"\"\n",
    "    multipolygons = []\n",
    "    for gl in gpoly:\n",
    "        ltln = gl[\"Boundary\"][\"Points\"]\n",
    "        points = [(p[\"Longitude\"], p[\"Latitude\"]) for p in ltln]\n",
    "        multipolygons.append(Polygon(points))\n",
    "    return MultiPolygon(multipolygons)\n",
    "\n",
    "def convert_list_gdf(datag):\n",
    "    \"\"\"converts List[] to geopandas dataframe\"\"\"\n",
    "    # create pandas dataframe from json\n",
    "    df = pd.json_normalize([vars(granule)['render_dict'] for granule in datag])\n",
    "    # keep only last string of the column names\n",
    "    df.columns=df.columns.str.split('.').str[-1]\n",
    "    # convert polygons to multipolygonal geometry\n",
    "    df[\"geometry\"] = df[\"GPolygons\"].apply(convert_umm_geometry)\n",
    "    # return geopandas dataframe\n",
    "    return gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ade2c-cc5a-4e11-af5c-db0c80dd5abb",
   "metadata": {},
   "source": [
    "Now, we will convert the JSON return from the `earthaccess` granule search into a geopandas dataframe so we could plot over an ESRI basemap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bc61c-7f09-4f14-933a-85d080f1abd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = convert_list_gdf(l2)\n",
    "#plot\n",
    "gdf[['BeginningDateTime','geometry']].explore(tiles=xyz, attr=attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a119271-9c03-4e9f-a479-f68f35d6d324",
   "metadata": {},
   "source": [
    "The above shows the flight lines of all LVIS collection during the BioSCape campaign in 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b7512-dc78-4272-939f-6a6081a48dcb",
   "metadata": {},
   "source": [
    "### Search LVIS L2A granules over a study area\n",
    "The study area is [Brackenburn Private Nature Reserve](https://plcnetwork.co.za/member/121/Brackenburn-Private-Nature-Reserve/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc84551-a715-4232-9160-ddec92a411b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_f = \"assets/brackenburn.json\"\n",
    "poly = gpd.read_file(poly_f)\n",
    "poly.explore(tiles=xyz, attr=attr, style_kwds={'color':'red', 'fill':False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d815fe0-5f12-4062-9d3a-0d5dae1acc45",
   "metadata": {},
   "source": [
    "Let's search for LVIS L2A granules that are within the bounds of the study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958af12e-c8ad-436b-870b-3a42f88a9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.geometry = poly.geometry.apply(orient, args=(1,))\n",
    "# simplifying the polygon to bypass the coordinates \n",
    "# limit of the CMR with a tolerance of .005 degrees\n",
    "xy = poly.geometry.simplify(0.005).get_coordinates()\n",
    "\n",
    "granules = earthaccess.search_data(\n",
    "    count=-1, # needed to retrieve all granules\n",
    "    doi=\"10.5067/VP7J20HJQISD\", # LVIS L2A doi\n",
    "    temporal=(\"2023-10-01\", \"2023-11-30\"), # Bioscape campaign dates\n",
    "    polygon=list(zip(xy.x, xy.y))\n",
    ")\n",
    "print(f'Granules found: {len(granules)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7b230-e300-4e07-8ac2-06207e0f04ac",
   "metadata": {},
   "source": [
    "Let's check when these LVIS flights were flown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808300e-57bd-4b09-9b9a-b31701adfe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = convert_list_gdf(granules)\n",
    "gdf['BeginningDateTime'] = pd.to_datetime(gdf['BeginningDateTime'])\n",
    "gdf_daily = gdf.resample(rule='D', on='BeginningDateTime')['concept-id'].nunique()\n",
    "gdf_daily.index = pd.to_datetime(gdf_daily.index).date\n",
    "gdf_daily.plot(kind=\"bar\", xlabel=\"Day of Flight\", ylabel=\"No. of flights\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8a815-89b1-45a4-8213-18ffdb08c11b",
   "metadata": {},
   "source": [
    "Let's plot these flight lines over a basemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3173d5f-e580-4c0a-bf8e-9ef8234e8caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gdf[['BeginningDateTime','geometry']].explore(tiles=xyz, attr=attr, \n",
    "                                              style_kwds={'fillOpacity':0.1})\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436ad156-cfa1-4db8-8982-3130fae5281c",
   "metadata": {},
   "source": [
    "### Download L2 granules\n",
    "In the above section, we retrieved the overlapping granules using the `earthaccess` module, which we will also use to download the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16233465-aa03-4220-ad25-4ff9fac27ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_files = earthaccess.download(granules, local_path=\"downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1435610-147a-43cb-93eb-8d1d324dd6b2",
   "metadata": {},
   "source": [
    "Earthaccess download uses a parallel downloading feature so all the files are downloaded efficiently. It also avoids duplicated downloads if a file has already been downloaded previously to the local path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c07b48-d51b-41d1-96ed-6fb513275d4c",
   "metadata": {},
   "source": [
    "### Read LVIS L2A Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325ab49-81a7-4f1e-b2da-c730b4a128e9",
   "metadata": {},
   "source": [
    "Now, we can read the LVIS L2A files into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb18f18-504e-461b-9d6c-f451d3941c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the LVIS L2A files\n",
    "lvis_l2a = []\n",
    "for s in gdf.index:\n",
    "    f = path.join('downloads', path.basename(granules[s].data_links()[0]))\n",
    "    h_no, col_names = get_line_number(f)\n",
    "    temp_df = pd.read_csv(f, skiprows=h_no, header=None, \n",
    "                          engine='python', sep=r'\\s+')\n",
    "    temp_df.columns =  [x.decode() for x in col_names]\n",
    "    temp_gdf = gpd.GeoDataFrame(temp_df, \n",
    "                                geometry=gpd.points_from_xy(temp_df.GLON, \n",
    "                                                            temp_df.GLAT),\n",
    "                                crs=\"EPSG:4326\")\n",
    "    temp_sub = gpd.sjoin(temp_gdf, poly, predicate='within')\n",
    "    if not temp_sub.empty:\n",
    "        print(f'Subsetting {path.basename(f)}')\n",
    "        lvis_l2a.append(temp_sub)\n",
    "lvis_l2a_gdf = pd.concat(lvis_l2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ec317-b542-497e-bbb0-4698adf27407",
   "metadata": {},
   "source": [
    "### Height of Top Canopy\n",
    "Let's plot RH100 (height of top canopy) values in a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f62ec-95fc-4331-abeb-6a479110a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvis_l2a_gdf[['RH100', 'geometry']].sample(frac=0.1, random_state=1).explore(\n",
    "    \"RH100\", cmap = \"YlGn\", tiles=xyz, attr=attr, alpha=0.5, radius=10, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c406465-f09c-415a-8c87-3530049a3a73",
   "metadata": {},
   "source": [
    "### Relative Height Distribution\n",
    "We can generate a plot of RH metrics to check if the vegetation height across the percentile of waveform energy indicates the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d8c33-5920-4cc7-952c-5f16cf9f4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 8))\n",
    "plot_df = lvis_l2a_gdf.sample(frac=0.1, random_state=1).filter(like='RH').drop('CHANNEL_RH', axis=1).T\n",
    "plot_df.index = plot_df.index.str.strip('RH').astype(int)\n",
    "std_df = plot_df.std(axis=1)\n",
    "median_df = plot_df.median(axis=1)\n",
    "median_df.plot(ax=ax, alpha=0.5, style='o-')\n",
    "ax.fill_between(plot_df.index, median_df - std_df, median_df + std_df, alpha=0.1)\n",
    "ax.set_xlabel(\"Percentile of waveform energy (%)\")\n",
    "ax.set_ylabel(\"Height (m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85818335-7cce-442f-a9f7-2f7e60c6cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting \n",
    "# lvis_l2a_gdf.geometry.to_file('lvis2.geojson', driver=\"GeoJSON\")\n",
    "# lvis_l2a_gdf.to_csv('lvis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663751cc-12ca-4925-850c-dd866ed3a218",
   "metadata": {},
   "source": [
    "## GEDI L2A Canopy Height Metrics\n",
    "This section of the tutorial will demonstrate how to directly access and subset the GEDI L2A canopy height metrics using [NASA’s Harmony Services](https://harmony.earthdata.nasa.gov) and compute a summary of aboveground biomass density for a forest reserve. The Harmony API allows seamless access and production of analysis-ready Earth observation data across different DAACs by enabling cloud-based spatial, temporal, and variable subsetting and data conversions. The GEDI datasets are available from the Harmony API.\n",
    "\n",
    "We will use NASA’s Harmony Services to retrieve the GEDI L2A dataset and canopy heights (`RH100`) for the burned and unburned plots . The Harmony API allows access to selected variables for the dataset within the spatial-temporal bounds without having to download the whole data file.\n",
    "\n",
    "### Dataset\n",
    "The GEDI Level 2A Geolocated Elevation and Height Metrics product [GEDI02_A](https://doi.org/10.5067/GEDI/GEDI02_A.002) provides waveform interpretation and extracted products from eachreceived waveform, including ground elevation, canopy top height, and relative height (RH) metrics. GEDI datasets are available for the period starting 2019-04-17 and covers 52 N to 52 S latitudes. GEDI L2A data files are natively in HDF5 format.\n",
    "\n",
    "### Authentication\n",
    "NASA Harmony API requires [NASA Earthdata Login (EDL)](https://urs.earthdata.nasa.gov/). You can use the `earthaccess` Python library to set up authentication. Alternatively, you can also login to `harmony_client` directly by passing EDL authentication as the following in the Jupyter Notebook itself:\n",
    "```\n",
    "harmony_client = Client(auth=(\"your EDL username\", \"your EDL password\"))\n",
    "```\n",
    "\n",
    "### Create Harmony Client Object\n",
    "First, we create a Harmony Client object. If you are passing the EDL authentication, please do as shown above with the auth parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e8a59-4348-4fcd-98d5-25964c7278f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61907fae-2eec-4fa2-a65b-8f616c37e3bf",
   "metadata": {},
   "source": [
    "### Retrieve Concept ID\n",
    "Now, let’s retrieve the `Concept ID` of the GEDI L2A dataset. The `Concept ID` is NASA Earthdata’s unique ID for its dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3b74b-d773-43d4-bb34-2f28a494ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_id(doi):\n",
    "    \"\"\"get concept id from DOI using CMR API\"\"\"\n",
    "    doisearch = f'https://cmr.earthdata.nasa.gov/search/collections.json?doi={doi}' \n",
    "    return re.get(doisearch).json()['feed']['entry'][0]['id']\n",
    "\n",
    "concept_l2a = get_concept_id('10.5067/GEDI/GEDI02_A.002') # GEDI L2A DOI\n",
    "print(f\"{concept_l2a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d23777-4d1e-44b0-87ea-3ae12c385576",
   "metadata": {},
   "source": [
    "### Define Request Parameters\n",
    "Let’s create a Harmony Collection object with the concept_id retrieved above. We will also define the GEDI L2A RH variables and temporal range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e89ce3-238a-4c61-a408-4b2dcdc280a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# harmony collection\n",
    "collection_l2a = Collection(id=concept_l2a)\n",
    "\n",
    "def create_var_names(variables):\n",
    "    # gedi beams\n",
    "    beams = ['BEAM0000', 'BEAM0001', 'BEAM0010', 'BEAM0011', 'BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011']\n",
    "    # combine variables and beam names\n",
    "    return [f'/{b}/{v}' for b in beams for v in variables]\n",
    "\n",
    "# gedi variables\n",
    "variables_l2a = create_var_names(['rh', 'quality_flag', 'land_cover_data/pft_class'])\n",
    "\n",
    "# time range\n",
    "temporal_range = {'start': datetime(2019, 4, 17), \n",
    "                  'stop': datetime(2023, 3, 31)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789de67-0da0-44e5-8385-d54912c54143",
   "metadata": {},
   "source": [
    "### Create and Submit Harmony Request\n",
    "Now, we can create a Harmony request with variables, temporal range, and bounding box and submit the request using the Harmony client object. We will use the `download_all` method, which uses a multithreaded downloader and returns a [concurrent future](https://docs.python.org/3/library/concurrent.futures.html). Futures are asynchronous and let us use the downloaded file as soon as the download is complete while other files are still being downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503847e-61f5-40fd-999e-f619896c7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_harmony(collection, variables):\n",
    "    \"\"\"submit harmony request\"\"\"\n",
    "    request = Request(collection=collection, \n",
    "                  variables=variables, \n",
    "                  temporal=temporal_range,\n",
    "                  shape=poly_f,\n",
    "                  ignore_errors=True)\n",
    "    # submit harmony request, will return job id\n",
    "    subset_job_id = harmony_client.submit(request)\n",
    "    return harmony_client.result_urls(subset_job_id, show_progress=True, \n",
    "                                      link_type=LinkType.s3)\n",
    "\n",
    "results = submit_harmony(collection_l2a, variables_l2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534256be-d904-40bb-afc8-925bc3eeac22",
   "metadata": {},
   "source": [
    "A temporary S3 Credentials is needed for read-only, same-region (**us-west-2**), direct access to S3 objects on the Earthdata cloud. We will use the credentials from the `harmony_client`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc04f6-ba53-4615-8e18-f8251111ebfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3credentials = harmony_client.aws_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09711f2c-8eda-469e-9a6a-32ebc0485fb7",
   "metadata": {},
   "source": [
    "We will pass S3 credentials to [S3Fs](https://s3fs.readthedocs.io/) class S3FileSystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47707d-6375-4e19-95f5-e54271a917f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_s3 = s3fs.S3FileSystem(anon=False, \n",
    "                          key=s3credentials['aws_access_key_id'], \n",
    "                          secret=s3credentials['aws_secret_access_key'], \n",
    "                          token=s3credentials['aws_session_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734dfca8-4ea7-4343-bf11-6bf0d6303303",
   "metadata": {},
   "source": [
    "### Read Subset files\n",
    "First, we will define a python function to read the GEDI variables, which are organized in a hierarchical way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970a81-5b36-45a9-986e-b41a3790d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gedi_vars(beam):\n",
    "    \"\"\"reads through gedi variable hierarchy\"\"\"\n",
    "    col_names = []\n",
    "    col_val = []\n",
    "    # read all variables\n",
    "    for key, value in beam.items():\n",
    "        # check if the item is a group\n",
    "        if isinstance(value, h5py.Group):\n",
    "            # looping through subgroups\n",
    "            for key2, value2 in value.items():\n",
    "                col_names.append(key2)\n",
    "                col_val.append(value2[:].tolist())\n",
    "        else:\n",
    "            col_names.append(key)\n",
    "            col_val.append(value[:].tolist())\n",
    "    return col_names, col_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642650d1-a8c5-464b-b6bc-94dd4323717d",
   "metadata": {},
   "source": [
    "Let’s direct access the subsetted h5 files and retrieve its values into the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b3aeb-5ccc-4190-b075-03b571c9a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an empty pandas dataframe\n",
    "subset_df = pd.DataFrame()\n",
    "# loop through the Harmony results\n",
    "for s3_url in results:\n",
    "    print(s3_url)\n",
    "    with fs_s3.open(s3_url, mode='rb') as fh:\n",
    "        with h5py.File(fh) as l2a_in:\n",
    "            for v in list(l2a_in.keys()):\n",
    "                if v.startswith('BEAM'):\n",
    "                    c_n, c_v = read_gedi_vars(l2a_in[v])\n",
    "                    # Appending to the subset_df dataframe\n",
    "                    subset_df = pd.concat([subset_df, \n",
    "                                           pd.DataFrame(map(list, zip(*c_v)), \n",
    "                                                        columns=c_n)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc7afe-f82a-4cf7-892b-fd8c4680b026",
   "metadata": {},
   "source": [
    "Let's remove the duplicate columns, if any, and print the first two rows of the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e46f321-4227-4024-aa60-11589dd4fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate columns\n",
    "subset_df = subset_df.loc[:,~subset_df.columns.duplicated()].copy()\n",
    "subset_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817fc05-4118-4c7e-9c46-9bcfc8f25666",
   "metadata": {},
   "source": [
    "### RH metrics\n",
    "Let's first split the `rh` variables into different columns. There are a total of 101 steps of percentiles defined starting from 0 to 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea7fe3-8114-40af-ad99-a5a6d916e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rh metrics column\n",
    "rh = []\n",
    "# loop through each percentile and create a RH column\n",
    "for i in range(101):\n",
    "    y = pd.DataFrame({f'RH{i}':subset_df['rh'].apply(lambda x: x[i])})\n",
    "    rh.append(y)\n",
    "rh = pd.concat(rh, axis=1)\n",
    "\n",
    "# concatenate RH columns to the original dataframe\n",
    "subset_df = pd.concat([subset_df, rh], axis=1)\n",
    "# print the first row of dataframe\n",
    "subset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a56b6-15a6-4783-942a-8dd18ad608b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gedi_gdf = gpd.GeoDataFrame(subset_df, \n",
    "                                geometry=gpd.points_from_xy(subset_df.lon_lowestmode, \n",
    "                                                            subset_df.lat_lowestmode),\n",
    "                                crs=\"EPSG:4326\")\n",
    "gedi_sub = gpd.sjoin(gedi_gdf, poly, predicate='within')\n",
    "gedi_sub[gedi_sub.quality_flag==1].explore(\"RH100\", cmap = \"YlGn\", tiles=xyz, attr=attr, alpha=0.5, radius=10, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfe8cf-3ccd-45e0-9a75-3b011323e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 10))\n",
    "plot_df = gedi_sub[gedi_sub.quality_flag==1].filter(like='RH').T\n",
    "plot_df.index = plot_df.index.str.strip('RH').astype(int)\n",
    "plot_df.median(axis=1).plot(ax=ax, alpha=0.5, style='s:')\n",
    "ax.set_xlabel(\"Percentile of waveform energy (%)\")\n",
    "ax.set_ylabel(\"Height (m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528076e8-4421-44f9-af25-a68050b89c17",
   "metadata": {},
   "source": [
    "## GEDI Waveform Structural Complexity Index (WSCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30e401-0e72-40a2-be1b-9d004f69e283",
   "metadata": {},
   "source": [
    "GEDI WSCI product ([GEDI L4C](https://daac.ornl.gov/GEDI/guides/GEDI_L4C_WSCI.html)) provides inference on forest structural complexity, which affects ecosystem functions, nutrient cycling, biodiversity, and habitat quality ([Tiago et al. 2024](https://www.nature.com/articles/s41467-024-52468-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a006b7-b2fe-4b86-9fb1-62f30966ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_l4c = get_concept_id('10.3334/ORNLDAAC/2338') # GEDI L4C DOI\n",
    "# harmony collection\n",
    "collection_l4c = Collection(id=concept_l4c)\n",
    "# gedi variables\n",
    "variables_l4c = create_var_names(['wsci'])\n",
    "# define an empty pandas dataframe\n",
    "subset_df2 = pd.DataFrame()\n",
    "# submit harmony\n",
    "results2 = submit_harmony(collection_l4c, variables_l4c)\n",
    "# loop through the Harmony results\n",
    "for s3_url in results2:\n",
    "    print(s3_url)\n",
    "    with fs_s3.open(s3_url, mode='rb') as fh:\n",
    "        with h5py.File(fh) as l4c_in:\n",
    "            for v in list(l4c_in.keys()):\n",
    "                if v.startswith('BEAM'):\n",
    "                    c_n, c_v = read_gedi_vars(l4c_in[v])\n",
    "                    # Appending to the subset_df dataframe\n",
    "                    subset_df2 = pd.concat([subset_df2, \n",
    "                                           pd.DataFrame(map(list, zip(*c_v)), \n",
    "                                                        columns=c_n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ccdab-df3a-4215-bc65-a1f96e955f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate columns\n",
    "subset_df2 = subset_df2.loc[:,~subset_df2.columns.duplicated()].copy()\n",
    "gedi_gdf2 = gpd.GeoDataFrame(subset_df2, \n",
    "                                geometry=gpd.points_from_xy(subset_df2.lon_lowestmode, \n",
    "                                                            subset_df2.lat_lowestmode),\n",
    "                                crs=\"EPSG:4326\")\n",
    "gedi_sub2 = gpd.sjoin(gedi_gdf2, poly, predicate='within')\n",
    "gedi_sub2[gedi_sub2.quality_flag==1].explore(\"WSCI\", cmap = \"YlGn\", tiles=xyz, attr=attr, alpha=0.5, radius=10, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c15d9-fdd7-427f-8bf4-eac0c3068bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
